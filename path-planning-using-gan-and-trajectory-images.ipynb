{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25c7d66cd9316a04e175245738b2e137f8614713"
   },
   "source": [
    "# Path planning using Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d2c2d42ade7504ca912701d016c396b9a3ee17d"
   },
   "source": [
    "In this notebook, I employ the concept of Generative Adversarial Network for path planning, i.e., generate paths between two points and classify them to be sure we get the right path.  The idea is to train the GAN based on the training data and later inqure the GAN to generate possible paths between two points. The potential applications of this work would be way finding and navigation for robots and autonomous vehicles. Training data includes different trajectories between 6 pairs of specified points. We treat each trajectory sample as an image. For more information about the data structure and experiment setup see the [dataset description](https://www.kaggle.com/datasets/mehdimka/path-planning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62275ca561cbdb5885225e44c41196be117dffa5"
   },
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "50a04676ef8767a1788f12c456e120a6e82188d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a1f8bd6664dba473f9ab2c773a2c07c4a782167a"
   },
   "source": [
    "## Loading data\n",
    "Here we load all csv files into feature and label vectors. Note that all CSV files in the original dataset are zipped in dataset.zip file but when used in kaggle kernels they are unzipped automattically under dataset/dataset folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "89e7394505d86a7ae5a475d3c023551a2a445fce"
   },
   "outputs": [],
   "source": [
    "data_path = \"../input/dataset/dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "129a3712f67bbb8f3a222e21cc33571319b8f63f"
   },
   "source": [
    "### See how a trajectory data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7bbf090dbf03b4c8a3b475ca78a6f687a825ad61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10  11  12\n",
       "0    1   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1    1   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "2    1   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "3    1   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "4    1   1   1   1   1   0   0   0   0   0   0   0   0\n",
       "5    0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "6    0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "7    0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "8    0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "9    0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "10   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "11   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
       "12   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
       "13   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
       "14   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "15   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "16   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "17   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "18   0   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = os.path.join(data_path, \"00_010.csv\")\n",
    "sample_df = pd.read_csv(sample_data, index_col=None, header=None)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb34c6a51823b65d1b877be3279dda73e5b7ecd3"
   },
   "source": [
    "And see how it looks like visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b121c62f3c23a91ce3cceb4abcb43fff49e412c3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMQAAAD8CAYAAAAojwurAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAAv5JREFUeJzt3bFtwgAQQFGImII+PVswbCZAWYIpUKbAFGl+QYGdIBvzXm2hE9LXFZzwdhiGDfDrY+4BYEkEASEICEFACAJCEBCCgBAEhCAgdnMPcM/15/Phn8+P+8MzR2Elvq9f20eesyEgBAEhCAhBQAgCQhAQgoAQBIQgIAQBIQgIQUAIAkIQEIKAEASEICAEASEICEFACAJCEBCCgBAEhCAgBAEhCAhBQAgCQhAQgoAQBIQgIAQBIQgIQUAIAkIQEIKAEASEICAEASEICEFACAJiN/cAf3W6nOceYZLj/jD3CNxhQ0AIAkIQEIKAEASEICAEASEICEFACAJikacb73DWMPbk5B2+kyWwISAEASEICEFACAJCEBCCgBAEhCAgBAEhCIhF3jK9g7G3SWNun9w9TWdDQAgCQhAQgoAQBIQgIAQBIQgIQUAIAsLpxosYc47hL26msyEgBAEhCAhBQAgCQhAQgoAQBIQgIAQBIQgIQUAIAkIQEIKAEASEICAEASEICEFACAJCEBCCgBAEhCAgBAEhCAhBQAgCQhAQgoAQBIQgIAQBIQgIQUAIAkIQEIKAEASEICAEASEICEFACAJiN/cA/L/j/jDq+dPl/LTPfjU2BIQgIAQBIQgIQUAIAkIQEIKAEASEICAEASEICEFACAJCEBCCgBAEhCAgBAEhCAhBQAgCQhAQgoAQBIQgIAQBIQgIQUAIAkIQEIKAEASEICC8UmuFxrwia7NZ/2uyxrAhIAQBIQgIQUAIAkIQEIKAEASEICAEAeF0Y4WcYkxnQ0AIAkIQEIKAEASEICAEASEICEFACAJCEBCCgBAEhCAgBAEhCAhBQAgCQhAQgoAQBIQgIAQBIQgIQUAIAkIQEIKAEASEICAEASEICEFACAJCEBCCgBAEhCAgBAEhCAhBQAgCQhAQgoAQBMR2GIa5Z4DFsCEgBAEhCAhBQAgCQhAQgoAQBIQgIAQBIQgIQUAIAkIQEIKAEASEICAEASEICEFACAJCEBCCgLgBKSUi1kFqZrsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(sample_df.values, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15c8404399f7c1921d01a31be1d4828ada04d415"
   },
   "source": [
    "Now load all tragectories and identify their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "def loadData(path=data_path):\n",
    "    files = os.listdir(path)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for fn in files:\n",
    "        ffn = os.path.join(path, fn)\n",
    "        df = pd.read_csv(ffn, index_col=None, header=None)\n",
    "        df[df==2]=0\n",
    "        data.append(df.values)\n",
    "        label = int(fn[0:2])\n",
    "        labels.append(label)\n",
    "    data = np.array(data) \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data, labels = loadData() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "ef39faaa418db68cc8df6abd8162de2edcdfded4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 2, 0, 5, 1, 5, 3, 4, 4, 0, 5, 5, 5, 3, 4, 0, 0, 0, 4, 1, 2, 5, 2, 0, 1, 1, 1, 5, 2, 4, 3, 5, 3, 1, 4, 3, 2, 2, 0, 3, 0, 4, 4, 3, 2, 5, 0, 1, 3, 5, 4, 3, 2, 1, 5, 0, 4, 2, 4, 2, 4, 3, 1, 4, 1, 5, 4, 1, 0, 2, 0, 5, 2, 5, 4, 5, 2, 5, 2, 2, 0, 2, 3, 2, 4, 3, 3, 4, 5, 0, 3, 5, 5, 2, 2, 2, 5, 1, 4, 3, 1, 3, 4, 0, 3, 3, 4, 0, 3, 5, 0, 3, 5, 3, 4, 2, 0, 0, 2, 5, 3, 1, 2, 5, 3, 1, 4, 2, 5, 3, 4, 0, 2, 4, 4, 2, 4, 3, 1, 4, 0, 1, 2, 3, 3, 4, 2, 1, 4, 3, 5, 1, 2, 0, 2, 4, 3, 2, 0, 0, 1, 3, 4, 0, 2, 1, 2, 4, 3, 3, 5, 5, 1, 2, 0, 5, 1, 3, 2, 0, 4, 2, 0, 2, 5, 1, 0, 0, 0, 2, 0, 5, 5, 0, 2, 0, 5, 3, 3, 0, 1, 1, 3, 4, 4, 5, 3, 2, 3, 0, 1, 0, 0, 5, 3, 1, 4, 5, 5, 2, 5, 2, 4, 2, 5, 3, 2, 3, 5, 3, 1, 0, 1, 5, 1, 1, 3, 5, 4, 5, 4, 1, 0, 4, 1, 4, 5, 0, 1, 1, 2, 5, 3, 4, 0, 1, 1, 5, 4, 3, 4, 4, 4, 1, 3, 1, 1, 2, 1, 0, 1, 4, 0, 1, 0, 5, 2, 4, 2, 2, 3, 0, 1, 0, 4, 0, 3, 2, 0, 0, 3, 3, 4, 1, 5, 4, 4, 3, 5, 5, 0, 5, 1, 1, 2, 5, 4, 4, 5, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1732735aa352002f7e60dd7b9b3e102d3ff97845"
   },
   "source": [
    "### Load defined path classes ad their specification:\n",
    "We have 6 classes. (x1,y1) and (x2,y2) specify tow end of the path.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "08b50cb8b0969863ce0f9db7cf3b7536fc8fc52f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  x1  y1  x2  y2\n",
       "0      0   0   0  14   7\n",
       "1      1   0   0  16  12\n",
       "2      2   2   5  16  12\n",
       "3      3   2   5  16   8\n",
       "4      4   2   5  18   0\n",
       "5      5   4   0  10  10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defined_path_classes = pd.read_csv(\"../input/pathClasses.csv\", index_col=None)\n",
    "defined_path_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e2ab8acb67bf842d67c923876c8c940d1a5ba50"
   },
   "source": [
    "# Create GAN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "f5d71c308c9c3b15da8244a29b32e0ca2dc0c091"
   },
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, img_rows=19, img_cols=13, channels=1):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (100,)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, X_train, y_, epochs=1000, batch_size=2):\n",
    "\n",
    "        X_train = 2 * (X_train.astype(np.float32)) - 1\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d261fcf8e9e09d52017c675ebf7040c563b0a454"
   },
   "source": [
    "### Build and Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "6202a5360aa4200b230c014dd9c711a9e4478147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 247)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               126976    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 258,561\n",
      "Trainable params: 258,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 247)               253175    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 19, 13, 1)         0         \n",
      "=================================================================\n",
      "Total params: 943,095\n",
      "Trainable params: 939,511\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time: 197.71360206604004 seconds ---\n"
     ]
    }
   ],
   "source": [
    "gan = GAN()\n",
    "start_time = time.time()\n",
    "gan.train(data, labels, epochs=10000, batch_size=8)\n",
    "print(\"total training time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6602b29083c13fa830de8eb6b354cd469283bebe"
   },
   "source": [
    "Generate 12 paths from noise vectors of size 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "8745829b9ed789185c8e7a9fc0824f948aaddc09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 100)\n"
     ]
    }
   ],
   "source": [
    "gen_samples_row, gen_samples_col = 3,4\n",
    "count = gen_samples_row*gen_samples_col\n",
    "noise = np.random.normal(0, 1, (count, 100))\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c7dbed51351df54692f014e81d2fff484771723"
   },
   "source": [
    "A noise vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "b27ff232992aba0aafe6c5f446a0e641ceb38ef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79646073, -2.23725461,  0.68810812,  0.33380308,  0.64127182,\n",
       "       -0.80644527, -0.05885049, -0.82470099, -1.42570095,  1.14636398,\n",
       "       -0.92931357,  0.14625337, -1.49246267, -0.16189134, -0.18471568,\n",
       "       -0.77681296, -0.29455471,  0.24475361, -0.24443153, -0.04421801,\n",
       "       -1.76460013, -0.1070267 ,  1.29509601,  0.91068462,  0.30894917,\n",
       "       -1.29170434,  0.39671954,  0.78369528, -0.05229147, -1.27789263,\n",
       "       -0.8334399 ,  0.71829546,  0.59116938, -1.34397045, -1.83617777,\n",
       "        0.6337429 ,  1.42947436,  0.97041879,  2.47293275,  1.58518517,\n",
       "        0.96794822,  0.54753354, -1.64296071,  0.92653134, -0.08185655,\n",
       "        0.15770908,  0.2221284 ,  0.39548018, -0.23068761, -0.24575568,\n",
       "       -1.0306965 ,  1.35263924, -1.65640887,  1.13495049,  0.01048108,\n",
       "       -0.99144646, -0.46897825,  0.20930264,  0.56476895, -0.62344118,\n",
       "       -1.57529753, -1.18288715, -1.38644724, -0.79281343, -0.24392327,\n",
       "       -0.42394007, -1.29110073,  0.74222238,  1.47351567, -0.57500746,\n",
       "        0.09016319,  0.56401142, -1.32429581,  0.63387665,  0.39907404,\n",
       "        2.33914807,  1.10391001, -0.52267935,  0.22454019,  1.41316739,\n",
       "        1.91739281,  0.23239465,  0.8080152 ,  0.66953951,  0.45785055,\n",
       "       -1.62583459,  0.0486829 ,  0.49183344,  0.29644644, -1.26936525,\n",
       "        0.20050157, -0.95392161,  1.35544087, -1.28818897,  0.32304438,\n",
       "        0.77842807,  1.13615356, -0.9450162 , -0.40151341, -1.6405424 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "311b263efc46af8a9e63281ff8f4ffe882a0cf6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 19, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "# Generate images from noise data\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "print(gen_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6baed0d7a054aea32e4e7588fd15a7937a1aed59"
   },
   "source": [
    "Rescale image pixels in 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "367de38f7258b849dde1669b9bc21a198d0e3b51"
   },
   "outputs": [],
   "source": [
    "gen_imgs = 0.5 * gen_imgs + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "850ece6457ac2bedd0c99a9cc16587cafcee9fe1"
   },
   "source": [
    "Shape of a generated image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "649ded7c5af79a9288921ddcc687b8da512b47cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 13, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aadd4ba8356a032c1a7d8d4b2ad37d43aec5a036"
   },
   "source": [
    "Show the generated paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0d490c682138ca4bb6b43a294a37b0cae79f22dd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 324x360 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(gen_samples_row, gen_samples_col, figsize=(4.5,5))\n",
    "cnt = 0\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "for i in range(gen_samples_row):\n",
    "    for j in range(gen_samples_col):\n",
    "        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap=plt.cm.gray)\n",
    "        axs[i,j].axis('off')\n",
    "    autoAxis = axs[i,j].axis()\n",
    "    rec = Rectangle((autoAxis[0]-0.1,autoAxis[2]-0.2),(autoAxis[1]-autoAxis[0])+.2,(autoAxis[3]-autoAxis[2])+0.1,fill=False, lw=0.5)\n",
    "    rec = axs[i,j].add_patch(rec)\n",
    "    rec.set_clip_on(False)\n",
    "    cnt += 1\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec0a360c30b038fa4a5266e315fbbeb334f95f84"
   },
   "source": [
    "After generating paths, we need to identify the class of generated path so we can check if they are what we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ed53ebf24d77120d0154890b0d1f35b45200be1"
   },
   "source": [
    "## Create Path Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8ff353c6ebc199010b4f398069749506e5e0b090"
   },
   "outputs": [],
   "source": [
    "class PathClassifier:\n",
    "    \n",
    "    def __init__(self, num_pixels=13*19, num_classes=6):\n",
    "        self.model = self.build_classifier_base(num_pixels, num_classes)\n",
    "\n",
    "    def build_classifier_base(self, num_pixels, num_classes):\n",
    "        # fix random seed for reproducibility\n",
    "        seed = 7\n",
    "        np.random.seed(seed)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train_model(self, X_train, y_train, eps=10, batch_size=20):\n",
    "        num_classes = y_train.shape[1]\n",
    "        num_pixels = X_train.shape[1]        \n",
    "        self.model.fit(X_train, y_train, epochs=eps, batch_size=batch_size, verbose=2)\n",
    "        return self.model\n",
    "\n",
    "    def evaluate(self, X_test, y_test):        \n",
    "        scores = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        accuracy = scores[1] * 100\n",
    "        print(\"Classification accuracy: %.2f%%\" % accuracy)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b4b2d4352a2ebb710b1d051d10e76dab14803dc"
   },
   "source": [
    "### Train the path classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "3fb1830c68ca87ed1fb5f8043df535d5711b69a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 1.6325 - acc: 0.4932\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2471 - acc: 0.8402\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.8957 - acc: 0.9224\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.5911 - acc: 0.9452\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.3829 - acc: 0.9589\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2582 - acc: 0.9726\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1833 - acc: 0.9726\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1275 - acc: 0.9909\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0962 - acc: 0.9909\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0791 - acc: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f519935d550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_classifier = PathClassifier()\n",
    "lblEnc = LabelEncoder()\n",
    "labels = lblEnc.fit_transform(labels)\n",
    "\n",
    "num_pixels = data.shape[1] * data.shape[2]\n",
    "data = data.reshape(data.shape[0], num_pixels).astype('float32')\n",
    "labels = np_utils.to_categorical(labels)\n",
    "\n",
    "num_classes = labels.shape[1]\n",
    "\n",
    "lnx = int(len(data) * 0.7)\n",
    "X_train, X_test = data[:lnx], data[lnx:]\n",
    "y_train, y_test = labels[:lnx], labels[lnx:]\n",
    "\n",
    "path_classifier.train_model(X_train, y_train, eps=10, batch_size=i*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09e01458757eb4db4e9bad0e9be98c81644c38d6"
   },
   "source": [
    "How accurate is our path classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "dcc95e6340ba000cb136ec5ce405312d83549f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 94.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.68085017610105"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "855283b642aee6e7ffa3137770dc9b97ab1f7668"
   },
   "source": [
    "Now we can identify the class of generated paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "0c325bddaaf0dbb9b1a6b45ba5d4cefe775a7153"
   },
   "outputs": [],
   "source": [
    "gen_imgs2 = gen_imgs.reshape(gen_imgs.shape[0], gen_imgs.shape[1]*gen_imgs.shape[2]).astype('float32')\n",
    "classes = path_classifier.model.predict(gen_imgs2)\n",
    "classes = np.argmax(classes, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5359e02d4acd4c1ed74b8b8886be4a2ba9f338ab"
   },
   "source": [
    "Draw generated paths and their class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "6b37bcfed49e3023801e469545e7b0ce98cfc525"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 324x360 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(gen_samples_row, gen_samples_col, figsize=(4.5,5))\n",
    "cnt = 0\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "for i in range(gen_samples_row):\n",
    "    for j in range(gen_samples_col):\n",
    "        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap=plt.cm.gray)\n",
    "        axs[i,j].set_title('class ' + str(classes[cnt]))\n",
    "        axs[i,j].axis('off')\n",
    "    autoAxis = axs[i,j].axis()\n",
    "    rec = Rectangle((autoAxis[0]-0.1,autoAxis[2]-0.2),(autoAxis[1]-autoAxis[0])+.2,(autoAxis[3]-autoAxis[2])+0.1,fill=False, lw=0.5)\n",
    "    rec = axs[i,j].add_patch(rec)\n",
    "    rec.set_clip_on(False)\n",
    "    cnt += 1\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc1fee4be7663f06018279cae2ca6ab5a646e462"
   },
   "source": [
    "### *Chanllenge: How to automatically evaluate the accuracy of generative models? It is still an open research question.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
